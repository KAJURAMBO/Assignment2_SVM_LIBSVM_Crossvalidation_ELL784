{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from libsvm.svmutil import * \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data=open('iris_data.txt')\n",
    "# features_iris = pd.DataFrame(iris_data.data, columns=iris_data.feature_names)## input featurs\n",
    "# target_iris = pd.DataFrame(iris_data.target,columns = ['target'])## output classes\n",
    "# x=features_iris.to_numpy\n",
    "# y=target_iris.to_numpy\n",
    "\n",
    "lines_list=iris_data.readlines()\n",
    "load_iris().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix=[]\n",
    "for line in lines_list:\n",
    "        row=[]\n",
    "        for val in line.split(','):\n",
    "                var =float(val)\n",
    "                row.append(var)\n",
    "        matrix.append(row)\n",
    "iris_data.close()\n",
    "\n",
    "matrix_rows=len(matrix)\n",
    "matrix_cols=len(matrix[0])\n",
    "\n",
    "sepal_length=[row[0] for row in matrix]\n",
    "sepal_width=[row[1] for row in matrix]\n",
    "petal_length=[row[2] for row in matrix]\n",
    "petal_width=[row[3] for row in matrix]\n",
    "output=[row[4] for row in matrix]\n",
    "\n",
    "x=[]\n",
    "for row in matrix:\n",
    "        r=[]\n",
    "        r.append(row[0])\n",
    "        r.append(row[1])\n",
    "        r.append(row[2])\n",
    "        r.append(row[3])\n",
    "        x.append(r)\n",
    "\n",
    "Total_instances=matrix_rows\n",
    "Trainning_instances=int(matrix_rows*0.8)        \n",
    "testing_instances=int(matrix_rows-Trainning_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Train(ms)= 3.502368927001953\n"
     ]
    }
   ],
   "source": [
    "Tstart=time.time()\n",
    "\n",
    "prob=svm_problem(output[0:Trainning_instances],x[0:Trainning_instances])\n",
    "param=svm_parameter('-s 0 -c 1 -t 2 -g 1  -d 3 ')\n",
    "model=svm_train(prob,param)\n",
    "#s---> SVM type\n",
    "#d---> degree\n",
    "#t--->kernal type\n",
    "#c--->margin type(soft/hard\n",
    "#g---> gamma in kernal funtion\n",
    "Tend=time.time()\n",
    "print('Time to Train(ms)=',(Tend-Tstart)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 83.3333% (25/30) (classification)\n"
     ]
    }
   ],
   "source": [
    "p_label,p_acc,p_val=svm_predict(output[Trainning_instances:Total_instances],x[Trainning_instances:Total_instances],model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "report=metrics.confusion_matrix(output[Trainning_instances:Total_instances],p_label)\n",
    "# sklearn.metrics.confusion_matrix\n",
    "report\n",
    "cm_df = pd.DataFrame(report,\n",
    "                     index = ['T','F'], \n",
    "                     columns = ['T','F'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Card\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cm_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Desktop\\Gate 2021\\Applied\\College\\IITD\\APPLIED MECHANICS\\Sem 3\\Intro to ML\\assignment2\\Quest_1_1\\question1_iris.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/Gate%202021/Applied/College/IITD/APPLIED%20MECHANICS/Sem%203/Intro%20to%20ML/assignment2/Quest_1_1/question1_iris.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mReport Card\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Desktop/Gate%202021/Applied/College/IITD/APPLIED%20MECHANICS/Sem%203/Intro%20to%20ML/assignment2/Quest_1_1/question1_iris.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m True_Positive\u001b[39m=\u001b[39mcm_df\u001b[39m.\u001b[39miat[\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]  \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/Gate%202021/Applied/College/IITD/APPLIED%20MECHANICS/Sem%203/Intro%20to%20ML/assignment2/Quest_1_1/question1_iris.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m False_Positive\u001b[39m=\u001b[39mcm_df\u001b[39m.\u001b[39miat[\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Desktop/Gate%202021/Applied/College/IITD/APPLIED%20MECHANICS/Sem%203/Intro%20to%20ML/assignment2/Quest_1_1/question1_iris.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m True_Negative\u001b[39m=\u001b[39mcm_df\u001b[39m.\u001b[39miat[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm_df' is not defined"
     ]
    }
   ],
   "source": [
    "print('Report Card')\n",
    "True_Positive=cm_df.iat[1,1]  \n",
    "False_Positive=cm_df.iat[1,0]\n",
    "True_Negative=cm_df.iat[0,0]\n",
    "False_Negative=cm_df.iat[0,1]\n",
    "print('True Positive=',True_Positive)\n",
    "print('False Positive=',False_Positive)\n",
    "print('True Negative=',True_Negative)\n",
    "print('False Negative=',False_Negative)\n",
    "print('Confusion Matrix-->\\n',cm_df)\n",
    "\n",
    "\n",
    "precision=True_Positive/(True_Positive+False_Positive)\n",
    "Recall=True_Positive/(True_Positive+False_Negative)\n",
    "Accurecy=True_Positive+True_Negative/(Total_instances-Trainning_instances)\n",
    "F_score=2*True_Positive/(2*True_Positive+False_Positive+False_Negative)\n",
    "\n",
    "print('Precision=',precision)\n",
    "print('Recall=',Recall)\n",
    "print('Accuracy=',round(Accurecy*100,1))\n",
    "print('F Score=',F_score)\n",
    "print('Time to Train(ms)=',(Tend-Tstart)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout=open(\"svmoutput.txt\",\"w\")\n",
    "fout.write(\"Outpot \\t Predicted \\n\")\n",
    "for i in range(len(p_label)):\n",
    "        fout.write(str(output[i+Trainning_instances])+\"\\t\" +str(p_label[i])+'\\n')\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_save_model('Iris_model',model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nMetrics\")\n",
    "\n",
    "# m_total=Total_instances-Trainning_instances\n",
    "# print(\"Total Instances: \"+str(m_total))\n",
    "\n",
    "# m_tp=0\n",
    "# for i in range(m_total):\n",
    "#         if output[i]==0.0 and p_label[i]==0.0 :\n",
    "#                 m_tp+=1\n",
    "#         if output[i]==1.0 and p_label[i]==1.0 :\n",
    "#                 m_tp+=1\n",
    "#         if output[i]==2.0 and p_label[i]==2.0 :\n",
    "#                 m_tp+=1\n",
    "# print(\"True Positive :\"+str(m_tp))\n",
    "\n",
    "# m_fp=0\n",
    "# for i in range(m_total):\n",
    "#         if output[i]==0.0 and p_label[i]==1.0 :\n",
    "#                 m_fp+=1\n",
    "# print(\"False Positive :\"+str(m_fp))\n",
    "\n",
    "# m_fn=0\n",
    "# for i in range(m_total):\n",
    "#         if output[i]==1.0 and p_label[i]==0.0 :\n",
    "#                 m_fn+=1\n",
    "# print(\"False Negative :\"+str(m_fn))\n",
    "\n",
    "# m_tn=0\n",
    "# for i in range(m_total):\n",
    "#         if output[i]==0.0 and p_label[i]==0.0 :\n",
    "#                 m_tn+=1\n",
    "# print(\"True Negative :\"+str(m_tn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 76.6667% (23/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 23\n",
      "False Negative= 7\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  7  23\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 76.7\n",
      "F Score= 0.0\n",
      "Accuracy = 83.3333% (25/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 25\n",
      "False Negative= 5\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  5  25\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 83.3\n",
      "F Score= 0.0\n",
      "Accuracy = 0% (0/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 0\n",
      "False Negative= 30\n",
      "Confusion Matrix-->\n",
      "     T  F\n",
      "T   0  0\n",
      "F  30  0\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 0.0\n",
      "F Score= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\2742063986.py:32: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\2742063986.py:32: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\2742063986.py:32: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\2742063986.py:32: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n"
     ]
    }
   ],
   "source": [
    "## Varrying the kernal type\n",
    "## same kernal parameter\n",
    "# margin same\n",
    "# degree same=3\n",
    "\n",
    "t=[0,1,2,3]\n",
    "confusion_matrix=[]\n",
    "for i in t:\n",
    "\n",
    "        prob=svm_problem(output[0:Trainning_instances],x[0:Trainning_instances])\n",
    "        param=svm_parameter(f'-s 0 -c 1 -t {i} -g 1  -d 3 ')\n",
    "        model=svm_train(prob,param)\n",
    "\n",
    "        svm_save_model(f'Iris_model{i}',model)\n",
    "        p_label,p_acc,p_val=svm_predict(output[Trainning_instances:Total_instances],x[Trainning_instances:Total_instances],model)\n",
    "        report=metrics.confusion_matrix(output[Trainning_instances:Total_instances],p_label)\n",
    "# sklearn.metrics.confusion_matrix\n",
    "        cm_df = pd.DataFrame(report,\n",
    "                        index = ['T','F'], \n",
    "                        columns = ['T','F'])\n",
    "        confusion_matrix.append(cm_df)\n",
    "        print('Report Card')\n",
    "        True_Positive=cm_df.iat[0,0]  \n",
    "        False_Positive=cm_df.iat[0,1]\n",
    "        True_Negative=cm_df.iat[1,1]\n",
    "        False_Negative=cm_df.iat[1,0]\n",
    "        print('True Positive=',True_Positive)\n",
    "        print('False Positive=',False_Positive)\n",
    "        print('True Negative=',True_Negative)\n",
    "        print('False Negative=',False_Negative)\n",
    "        print('Confusion Matrix-->\\n',cm_df)\n",
    "\n",
    "\n",
    "        precision=True_Positive/(True_Positive+False_Positive)\n",
    "        Recall=True_Positive/(True_Positive+False_Negative)\n",
    "        Accurecy=True_Positive+True_Negative/(Total_instances-Trainning_instances)\n",
    "        F_score=2*True_Positive/(2*True_Positive+False_Positive+False_Negative)\n",
    "\n",
    "        print('Precision=',precision)\n",
    "        print('Recall=',Recall)\n",
    "        print('Accuracy=',round(Accurecy*100,1))\n",
    "        print('F Score=',F_score)\n",
    "        svm_save_model(f'Iris_model{i}',model)\n",
    "#s---> SVM type\n",
    "#d---> degree\n",
    "#t--->kernal type\n",
    "#c--->margin type(soft/hard\n",
    "#g---> gamma in kernal funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\3371299445.py:33: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n"
     ]
    }
   ],
   "source": [
    "# Varrying the kernel parameter\n",
    "# SVM type is fixed to linear(as not depending on svm type)\n",
    "# margin same\n",
    "# degree same=3\n",
    "\n",
    "\n",
    "g=np.linspace(1,15,num=15)\n",
    "confusion_matrix=[]\n",
    "for i in g:\n",
    "\n",
    "        prob=svm_problem(output[0:Trainning_instances],x[0:Trainning_instances])\n",
    "        param=svm_parameter(f'-s 0 -c 1 -t 0 -g {i}  -d 3 ')\n",
    "        model=svm_train(prob,param)\n",
    "\n",
    "        svm_save_model(f'Iris_model{i}',model)\n",
    "        p_label,p_acc,p_val=svm_predict(output[Trainning_instances:Total_instances],x[Trainning_instances:Total_instances],model)\n",
    "        report=metrics.confusion_matrix(output[Trainning_instances:Total_instances],p_label)\n",
    "# sklearn.metrics.confusion_matrix\n",
    "        cm_df = pd.DataFrame(report,\n",
    "                        index = ['T','F'], \n",
    "                        columns = ['T','F'])\n",
    "        confusion_matrix.append(cm_df)\n",
    "        print('Report Card')\n",
    "        True_Positive=cm_df.iat[0,0]  \n",
    "        False_Positive=cm_df.iat[0,1]\n",
    "        True_Negative=cm_df.iat[1,1]\n",
    "        False_Negative=cm_df.iat[1,0]\n",
    "        print('True Positive=',True_Positive)\n",
    "        print('False Positive=',False_Positive)\n",
    "        print('True Negative=',True_Negative)\n",
    "        print('False Negative=',False_Negative)\n",
    "        print('Confusion Matrix-->\\n',cm_df)\n",
    "\n",
    "\n",
    "        precision=True_Positive/(True_Positive+False_Positive)\n",
    "        Recall=True_Positive/(True_Positive+False_Negative)\n",
    "        Accurecy=True_Positive+True_Negative/(Total_instances-Trainning_instances)\n",
    "        F_score=2*True_Positive/(2*True_Positive+False_Positive+False_Negative)\n",
    "\n",
    "        print('Precision=',precision)\n",
    "        print('Recall=',Recall)\n",
    "        print('Accuracy=',round(Accurecy*100,1))\n",
    "        print('F Score=',F_score)\n",
    "        svm_save_model(f'Iris_model{i}',model)\n",
    "#s---> SVM type\n",
    "#d---> degree\n",
    "#t--->kernal type\n",
    "#c--->margin type(soft/hard\n",
    "#g---> gamma in kernal funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 83.3333% (25/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 25\n",
      "False Negative= 5\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  5  25\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 83.3\n",
      "F Score= 0.0\n",
      "Accuracy = 83.3333% (25/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 25\n",
      "False Negative= 5\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  5  25\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 83.3\n",
      "F Score= 0.0\n",
      "Accuracy = 83.3333% (25/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 25\n",
      "False Negative= 5\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  5  25\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 83.3\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 83.3333% (25/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 25\n",
      "False Negative= 5\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  5  25\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 83.3\n",
      "F Score= 0.0\n",
      "Accuracy = 83.3333% (25/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 25\n",
      "False Negative= 5\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  5  25\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 83.3\n",
      "F Score= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\4022680402.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n"
     ]
    }
   ],
   "source": [
    "# Varrying the margin\n",
    "# SVM type is fixed to linear(as not depending on svm type)\n",
    "# kernal parameter(gamma) same to 1\n",
    "# degree same=3\n",
    "\n",
    "\n",
    "c=np.linspace(1,15,num=15)\n",
    "confusion_matrix=[]\n",
    "for i in c:\n",
    "\n",
    "        prob=svm_problem(output[0:Trainning_instances],x[0:Trainning_instances])\n",
    "        param=svm_parameter(f'-s 0 -c {i} -t 0 -g 1  -d 3 ')\n",
    "        model=svm_train(prob,param)\n",
    "\n",
    "        svm_save_model(f'Iris_model{i}',model)\n",
    "        p_label,p_acc,p_val=svm_predict(output[Trainning_instances:Total_instances],x[Trainning_instances:Total_instances],model)\n",
    "        report=metrics.confusion_matrix(output[Trainning_instances:Total_instances],p_label)\n",
    "# sklearn.metrics.confusion_matrix\n",
    "        cm_df = pd.DataFrame(report,\n",
    "                        index = ['T','F'], \n",
    "                        columns = ['T','F'])\n",
    "        confusion_matrix.append(cm_df)\n",
    "        print('Report Card')\n",
    "        True_Positive=cm_df.iat[0,0]  \n",
    "        False_Positive=cm_df.iat[0,1]\n",
    "        True_Negative=cm_df.iat[1,1]\n",
    "        False_Negative=cm_df.iat[1,0]\n",
    "        print('True Positive=',True_Positive)\n",
    "        print('False Positive=',False_Positive)\n",
    "        print('True Negative=',True_Negative)\n",
    "        print('False Negative=',False_Negative)\n",
    "        print('Confusion Matrix-->\\n',cm_df)\n",
    "\n",
    "\n",
    "        precision=True_Positive/(True_Positive+False_Positive)\n",
    "        Recall=True_Positive/(True_Positive+False_Negative)\n",
    "        Accurecy=True_Positive+True_Negative/(Total_instances-Trainning_instances)\n",
    "        F_score=2*True_Positive/(2*True_Positive+False_Positive+False_Negative)\n",
    "\n",
    "        print('Precision=',precision)\n",
    "        print('Recall=',Recall)\n",
    "        print('Accuracy=',round(Accurecy*100,1))\n",
    "        print('F Score=',F_score)\n",
    "        svm_save_model(f'Iris_model_margin{i}',model)\n",
    "#s---> SVM type\n",
    "#d---> degree\n",
    "#t--->kernal type\n",
    "#c--->margin type(soft/hard\n",
    "#g---> gamma in kernal funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n",
      "Accuracy = 86.6667% (26/30) (classification)\n",
      "Report Card\n",
      "True Positive= 0\n",
      "False Positive= 0\n",
      "True Negative= 26\n",
      "False Negative= 4\n",
      "Confusion Matrix-->\n",
      "    T   F\n",
      "T  0   0\n",
      "F  4  26\n",
      "Precision= nan\n",
      "Recall= 0.0\n",
      "Accuracy= 86.7\n",
      "F Score= 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n",
      "C:\\Users\\rahma\\AppData\\Local\\Temp\\ipykernel_9572\\761513910.py:35: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  precision=True_Positive/(True_Positive+False_Positive)\n"
     ]
    }
   ],
   "source": [
    "# Varrying the degree\n",
    "# SVM type is fixed to linear(as not depending on svm type)\n",
    "# kernal parameter(gamma) same to 1\n",
    "# SVM type same\n",
    "\n",
    "\n",
    "d=[1,2,3,4,5,6,7,8,9,10]\n",
    "confusion_matrix=[]\n",
    "for i in d:\n",
    "\n",
    "        prob=svm_problem(output[0:Trainning_instances],x[0:Trainning_instances])\n",
    "        param=svm_parameter(f'-s 0 -c 1 -t 0 -g 1  -d {i} ')\n",
    "        model=svm_train(prob,param)\n",
    "\n",
    "        svm_save_model(f'Iris_model{i}',model)\n",
    "        p_label,p_acc,p_val=svm_predict(output[Trainning_instances:Total_instances],x[Trainning_instances:Total_instances],model)\n",
    "        report=metrics.confusion_matrix(output[Trainning_instances:Total_instances],p_label)\n",
    "# sklearn.metrics.confusion_matrix\n",
    "        cm_df = pd.DataFrame(report,\n",
    "                        index = ['T','F'], \n",
    "                        columns = ['T','F'])\n",
    "        confusion_matrix.append(cm_df)\n",
    "        print('Report Card')\n",
    "        True_Positive=cm_df.iat[0,0]  \n",
    "        False_Positive=cm_df.iat[0,1]\n",
    "        True_Negative=cm_df.iat[1,1]\n",
    "        False_Negative=cm_df.iat[1,0]\n",
    "        print('True Positive=',True_Positive)\n",
    "        print('False Positive=',False_Positive)\n",
    "        print('True Negative=',True_Negative)\n",
    "        print('False Negative=',False_Negative)\n",
    "        print('Confusion Matrix-->\\n',cm_df)\n",
    "\n",
    "\n",
    "        precision=True_Positive/(True_Positive+False_Positive)\n",
    "        Recall=True_Positive/(True_Positive+False_Negative)\n",
    "        Accurecy=True_Positive+True_Negative/(Total_instances-Trainning_instances)\n",
    "        F_score=2*True_Positive/(2*True_Positive+False_Positive+False_Negative)\n",
    "\n",
    "        print('Precision=',precision)\n",
    "        print('Recall=',Recall)\n",
    "        print('Accuracy=',round(Accurecy*100,1))\n",
    "        print('F Score=',F_score)\n",
    "        svm_save_model(f'Iris_model_degree{i}',model)\n",
    "#s---> SVM type\n",
    "#d---> degree\n",
    "#t--->kernal type\n",
    "#c--->margin type(soft/hard\n",
    "#g---> gamma in kernal funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be0c76a15e7db832c1cef9e000d0973fde535108692ea45e0855d7f2c98f1a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
